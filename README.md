# Human-Activity-Recognition
This project implements a robust Human Activity Recognition (HAR) system that automatically classifies human activities using multi-modal sensor data from smartphones and wearable devices. The system addresses key challenges in ubiquitous computing and ambient intelligence applications.
ğŸ” Problem Statement
Traditional activity monitoring methods are privacy-invasive, resource-intensive, and limited in scalability. Our solution provides:

Privacy-preserving activity recognition
Real-time processing capabilities
High accuracy classification
Energy-efficient mobile deployment

ğŸš€ Key Features
ğŸ¤– Multiple ML Approaches

Traditional ML: Random Forest, Support Vector Machine (SVM)
Deep Learning: Multi-Layer Perceptron (MLP), 1D CNN, LSTM
Ensemble Methods: Advanced voting mechanisms for optimal performance

ğŸ“Š Comprehensive Analysis

Feature Engineering: Time-domain, frequency-domain, and statistical features
Cross-Validation: 5-fold stratified validation
Performance Metrics: Accuracy, Precision, Recall, F1-Score
Visualization Suite: 15+ professional charts and graphs

âš¡ Real-time Capabilities

Low Latency: <15ms processing time per prediction
Energy Efficient: Only 7% additional battery consumption
Mobile Optimized: Designed for smartphone deployment

ğŸ¯ Activities Recognized

ğŸš¶ Walking
ğŸƒ Running/Jogging
ğŸ†™ Walking Upstairs
ğŸ†˜ Walking Downstairs
ğŸ’º Sitting
ğŸ§ Standing
ğŸ›ï¸ Laying Down

ğŸ› ï¸ Tech Stack
Core Technologies

Python 3.8+ - Main programming language
TensorFlow/Keras - Deep learning framework
Scikit-learn - Traditional ML algorithms
Pandas & NumPy - Data manipulation and analysis

Visualization & Analysis

Matplotlib & Seaborn - Data visualization
Plotly - Interactive charts
Jupyter Notebooks - Development environment

Mobile Development (Future)

Android Studio - Mobile app development
TensorFlow Lite - Mobile model deployment

ğŸš€ Quick Start
ğŸ”¥ Google Colab (Recommended)

Click the "Open in Colab" badge above
Run all cells - that's it! ğŸ‰

ğŸ’» Local Installation
bash# Clone the repository
git clone https://github.com/yourusername/human-activity-recognition.git
cd human-activity-recognition

# Install dependencies
pip install -r requirements.txt

# Run the main notebook
jupyter notebook HAR_Complete_Analysis.ipynb
ğŸ“¦ Requirements
tensorflow>=2.8.0
scikit-learn>=1.0.0
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.5.0
seaborn>=0.11.0
ucimlrepo>=0.0.3
ğŸ“ Project Structure
human-activity-recognition/
â”œâ”€â”€ ğŸ“Š data/
â”‚   â”œâ”€â”€ raw/                    # Raw sensor data
â”‚   â”œâ”€â”€ processed/              # Preprocessed datasets
â”‚   â””â”€â”€ external/               # External datasets
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â”œâ”€â”€ HAR_Complete_Analysis.ipynb    # Main analysis notebook
â”‚   â”œâ”€â”€ Data_Exploration.ipynb         # Data exploration
â”‚   â””â”€â”€ Model_Comparison.ipynb         # Model comparisons
â”œâ”€â”€ ğŸ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocessing.py    # Data preprocessing
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ traditional_ml.py   # ML models
â”‚   â”‚   â”œâ”€â”€ deep_learning.py    # DL models
â”‚   â”‚   â””â”€â”€ ensemble.py         # Ensemble methods
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ visualization.py    # Plotting functions
â”‚       â””â”€â”€ evaluation.py       # Evaluation metrics
â”œâ”€â”€ ğŸ“± mobile/
â”‚   â””â”€â”€ android/                # Android app code
â”œâ”€â”€ ğŸ“‹ reports/
â”‚   â”œâ”€â”€ figures/                # Generated figures
â”‚   â””â”€â”€ final_report.pdf        # Project report
â”œâ”€â”€ ğŸ”§ requirements.txt
â”œâ”€â”€ ğŸ“– README.md
â””â”€â”€ ğŸ“„ LICENSE
ğŸ“Š Data Sources
Primary Dataset

UCI HAR Dataset: 30 volunteers, 6 activities, 10,299 instances
Features: 561 time and frequency domain features
Sensors: Accelerometer, Gyroscope (50Hz sampling rate)

Secondary Dataset

WISDM Dataset: 29 users, 6 activities, 1M+ instances
Real-world smartphone data: Accelerometer only
Sampling rate: 20Hz
